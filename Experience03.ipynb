{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How fast is your Computing Machine?\n",
    "\n",
    "Our computers do basically two things, one is storing numbers, the other is doing mathematical operations on them. They are so useful because they do these things extraordinarily fast and extraordinarily well, in the sense that they always do them correctly following our instructions. For this reason the main way in which we use them is to give them repetitive instructions for up to billions of times.\n",
    "\n",
    "Since the speed of the CPU has doubled every 1.5 years until a few years ago (Moore’s Law), we may have lost track of how really fast the computer in our hands is. When starting this journey into numerical modeling, it is important to first quickly experiment this and not only realize how remarkably fast it really is, but also to perceive its limits when we reach them.\n",
    "\n",
    "In this chapter, we start using iPython because its interactive setting allows us to feel better about what the computer does. Later we will step into writing and running a program. Let us initially load NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's create a little function that simply counts up to a value *max*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function simply counts from 0 to max\n",
    "def count(max):\n",
    "    i=0\n",
    "    while i<max:\n",
    "        i=i+1\n",
    "    #print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I try to launch count(1000) or count(100000) on my laptop I simply do not observe any difference. Just the time to call the function, and I get the result. It is unnoticeable that the second call required 100 times more calculation than the first one. Only when I arrive at one million or better ten millions, I finally observe a lag. In fact what I notice is the time that it takes for one processor of my laptop to perform this serial calculation. You can test yours and perceive the power of your computer.\n",
    "\n",
    "We can also be more quantitative about the time required by our little routine. iPython offers a very simple and powerful magic command called %timeit. Let us test it for testing the time required by our loop:\n",
    "\n",
    "The %timeit command is used to calculate the average time of performing certain operations in python. As an example let us use this command to calculate the time that it takes to count from 0 to max in the above function. \n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Use the command %timeit to calculate how long it takes to the function *Count()* to count up to:\n",
    "\n",
    "a) 100000 \n",
    "\n",
    "b) 1000000 \n",
    "\n",
    "c) 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.37 ms ± 151 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "63.2 ms ± 1.72 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "622 ms ± 2.98 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#here put your solution for (a) and create two more cells for (b) and (c)\n",
    "\n",
    "# Define the function\n",
    "def count(max):\n",
    "    i=0\n",
    "    while i<max:\n",
    "        i=i+1\n",
    "        \n",
    "# Use the function, along with timeit\n",
    "%timeit count(100000)\n",
    "%timeit count(1000000)\n",
    "%timeit count(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the computing times that you find. Are they proportional to how much the funcion counts? Why? Can you now estimate how fast is your computer? \n",
    "\n",
    "Let's now create a sligtly more sophisticate function, which adds the first *max* numbers instead of simply counting them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# also this function counts, but increasingly larger numbers\n",
    "def addCount(max):\n",
    "    a=0.0\n",
    "    for i in range(max):\n",
    "        a=a+i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Use the command %timeit to calculate how long it takes to the function *addCount()* to sum numbers up to:\n",
    "\n",
    "a) 100000 \n",
    "\n",
    "b) 1000000 \n",
    "\n",
    "c) 10000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10)\n",
      "7.33 ms ± 988 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "69.5 ms ± 741 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "724 ms ± 29 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#here put your solution for (a) and create two more cells for (b) and (c)\n",
    "\n",
    "# Range is a function that returns a sequence of numbers, if only one number is given, then it assumes its the stop point.\n",
    "test=range(10)\n",
    "print(test)\n",
    "\n",
    "def addCount(max):\n",
    "    a=0\n",
    "    for i in range(max):\n",
    "        a=a+i\n",
    "    \n",
    "%timeit addCount(100000)\n",
    "%timeit addCount(1000000)\n",
    "%timeit addCount(10000000)\n",
    "\n",
    "# slightly faster, mostly the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, comments on the computing times that you find. Here...\n",
    "\n",
    "It takes almost the same! \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy \n",
    "\n",
    "Let's focus on the Numerical Tools of Python. Among others, NumPy adds to standard Python the following features:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">A. Multidimensional vectorized arrays<br />\n",
    ">B. Mathematical functions operating on an array or portions of it<br />\n",
    ">C. Linear Algebra, Fourier development, Random Functions<br />\n",
    "      D. Input/Output functions to efficiently create and read memory mapped files<br />\n",
    "      \n",
    "Let's start from the NumPy Types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Types\n",
    "\n",
    "Without any further specification, Python automatically uses float type machine precision. We might not know which precision this is, in which case it is important to discover it. A very straightforward way to discover the precision of our machine is by testing for which small ε, a and a + ε become indistinguishable. We can do so by iteratively decreasing ε of a certain ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Precision: 0.1111111111111111\n",
      "Precision: 0.012345679012345678\n",
      "Precision: 0.0013717421124828531\n",
      "Precision: 0.00015241579027587256\n",
      "Precision: 1.6935087808430286e-05\n",
      "Precision: 1.8816764231589206e-06\n",
      "Precision: 2.0907515812876894e-07\n",
      "Precision: 2.323057312541877e-08\n",
      "Precision: 2.5811747917131966e-09\n",
      "Precision: 2.867971990792441e-10\n",
      "Precision: 3.1866355453249343e-11\n",
      "Precision: 3.5407061614721493e-12\n",
      "Precision: 3.934117957191277e-13\n",
      "Precision: 4.371242174656974e-14\n",
      "Precision: 4.85693574961886e-15\n",
      "Precision: 5.396595277354289e-16\n",
      "Precision: 5.996216974838099e-17\n",
      "Precision: 6.6624633053756655e-18\n",
      "Precision: 7.402737005972962e-19\n",
      "Precision: 8.225263339969957e-20\n",
      "Precision: 9.139181488855508e-21\n",
      "Precision: 1.0154646098728343e-21\n",
      "Precision: 1.1282940109698158e-22\n",
      "Precision: 1.2536600121886843e-23\n",
      "Precision: 1.392955569098538e-24\n",
      "Precision: 1.5477284101094868e-25\n",
      "Precision: 1.7196982334549854e-26\n",
      "Precision: 1.9107758149499837e-27\n",
      "Precision: 2.1230842388333153e-28\n",
      "Precision: 2.3589824875925725e-29\n",
      "Precision: 2.621091652880636e-30\n",
      "Precision: 2.9123240587562624e-31\n",
      "Precision: 3.2359156208402915e-32\n",
      "Precision: 3.595461800933657e-33\n",
      "Precision: 3.994957556592953e-34\n",
      "Precision: 4.4388417295477253e-35\n",
      "Precision: 4.932046366164139e-36\n",
      "Precision: 5.480051517960155e-37\n",
      "Precision: 6.088946131066838e-38\n",
      "Precision: 6.765495701185375e-39\n",
      "Precision: 7.517217445761529e-40\n",
      "Precision: 8.352463828623921e-41\n",
      "Precision: 9.28051536513769e-42\n",
      "Precision: 1.0311683739041878e-42\n",
      "Precision: 1.1457426376713199e-43\n",
      "Precision: 1.2730473751903554e-44\n",
      "Precision: 1.4144970835448395e-45\n",
      "Precision: 1.5716634261609329e-46\n",
      "Precision: 1.74629269573437e-47\n",
      "Precision: 1.9403252174826334e-48\n",
      "Precision: 2.155916908314037e-49\n",
      "Precision: 2.395463231460041e-50\n",
      "Precision: 2.6616258127333788e-51\n",
      "Precision: 2.9573620141481986e-52\n",
      "Precision: 3.2859577934979986e-53\n",
      "Precision: 3.651064214997776e-54\n",
      "Precision: 4.056738016664196e-55\n",
      "Precision: 4.50748668518244e-56\n",
      "Precision: 5.0083185390916e-57\n",
      "Precision: 5.5647983767684445e-58\n",
      "Precision: 6.183109307520494e-59\n",
      "Precision: 6.870121452800549e-60\n",
      "Precision: 7.633468280889499e-61\n",
      "Precision: 8.481631423210554e-62\n",
      "Precision: 9.424034914678393e-63\n",
      "Precision: 1.0471149905198215e-63\n",
      "Precision: 1.1634611005775795e-64\n",
      "Precision: 1.2927345561973105e-65\n",
      "Precision: 1.4363717291081228e-66\n",
      "Precision: 1.5959685878979142e-67\n",
      "Precision: 1.7732984309976824e-68\n",
      "Precision: 1.970331589997425e-69\n",
      "Precision: 2.1892573222193612e-70\n",
      "Precision: 2.4325081357992902e-71\n",
      "Precision: 2.702786817554767e-72\n",
      "Precision: 3.003096463949741e-73\n",
      "Precision: 3.3367738488330452e-74\n",
      "Precision: 3.7075264987033837e-75\n",
      "Precision: 4.1194738874482043e-76\n",
      "Precision: 4.5771932082757826e-77\n",
      "Precision: 5.085770231417536e-78\n",
      "Precision: 5.650855812686151e-79\n",
      "Precision: 6.27872868076239e-80\n",
      "Precision: 6.9763652008471e-81\n",
      "Precision: 7.751516889830111e-82\n",
      "Precision: 8.612796544255678e-83\n",
      "Precision: 9.569773938061865e-84\n",
      "Precision: 1.0633082153402071e-84\n",
      "Precision: 1.1814535726002301e-85\n",
      "Precision: 1.3127261917780335e-86\n",
      "Precision: 1.4585846575311483e-87\n",
      "Precision: 1.6206496194790536e-88\n",
      "Precision: 1.8007217994211708e-89\n",
      "Precision: 2.0008019993568564e-90\n",
      "Precision: 2.2231133326187293e-91\n",
      "Precision: 2.4701259251319215e-92\n",
      "Precision: 2.7445843612576906e-93\n",
      "Precision: 3.049538179175212e-94\n",
      "Precision: 3.388375754639125e-95\n",
      "Precision: 3.764861949599027e-96\n",
      "Precision: 4.183179943998919e-97\n",
      "Precision: 4.6479777155543544e-98\n",
      "Precision: 5.164419683949283e-99\n",
      "Precision: 5.738244093276981e-100\n",
      "Precision: 6.375826770307757e-101\n",
      "Precision: 7.084251967008619e-102\n",
      "Precision: 7.871391074454021e-103\n",
      "Precision: 8.74599008272669e-104\n",
      "Precision: 9.717766758585212e-105\n",
      "Precision: 1.0797518620650235e-105\n",
      "Precision: 1.1997242911833593e-106\n",
      "Precision: 1.3330269902037326e-107\n",
      "Precision: 1.4811411002263697e-108\n",
      "Precision: 1.6457123335848551e-109\n",
      "Precision: 1.828569259538728e-110\n",
      "Precision: 2.0317436217096978e-111\n",
      "Precision: 2.2574929130107753e-112\n",
      "Precision: 2.5083254589008614e-113\n",
      "Precision: 2.787028287667624e-114\n",
      "Precision: 3.096698097408471e-115\n",
      "Precision: 3.44077566378719e-116\n",
      "Precision: 3.823084070874656e-117\n",
      "Precision: 4.247871189860729e-118\n",
      "Precision: 4.7198568776230323e-119\n",
      "Precision: 5.244285419581147e-120\n",
      "Precision: 5.8269837995346075e-121\n",
      "Precision: 6.474426443927341e-122\n",
      "Precision: 7.193807159919269e-123\n",
      "Precision: 7.993119066576966e-124\n",
      "Precision: 8.88124340730774e-125\n",
      "Precision: 9.868048230341933e-126\n",
      "Precision: 1.096449803371326e-126\n",
      "Precision: 1.2182775593014733e-127\n",
      "Precision: 1.3536417325571926e-128\n",
      "Precision: 1.5040463695079916e-129\n",
      "Precision: 1.6711626327866573e-130\n",
      "Precision: 1.8568473697629525e-131\n",
      "Precision: 2.0631637441810583e-132\n",
      "Precision: 2.292404160201176e-133\n",
      "Precision: 2.5471157335568623e-134\n",
      "Precision: 2.830128592840958e-135\n",
      "Precision: 3.1445873253788422e-136\n",
      "Precision: 3.4939859170876023e-137\n",
      "Precision: 3.88220657454178e-138\n",
      "Precision: 4.3135628606019784e-139\n",
      "Precision: 4.792847622891088e-140\n",
      "Precision: 5.325386247656764e-141\n",
      "Precision: 5.917095830729738e-142\n",
      "Precision: 6.574550923033042e-143\n",
      "Precision: 7.305056581147824e-144\n",
      "Precision: 8.116729534608694e-145\n",
      "Precision: 9.018588371787438e-146\n",
      "Precision: 1.0020653746430487e-146\n",
      "Precision: 1.1134059718256097e-147\n",
      "Precision: 1.2371177464728997e-148\n",
      "Precision: 1.3745752738587775e-149\n",
      "Precision: 1.5273058598430862e-150\n",
      "Precision: 1.6970065109367624e-151\n",
      "Precision: 1.885562789929736e-152\n",
      "Precision: 2.0950697665885954e-153\n",
      "Precision: 2.3278552962095505e-154\n",
      "Precision: 2.5865058846772782e-155\n",
      "Precision: 2.873895427419198e-156\n",
      "Precision: 3.193217141576886e-157\n",
      "Precision: 3.54801904619654e-158\n",
      "Precision: 3.9422433846628226e-159\n",
      "Precision: 4.380270427403136e-160\n",
      "Precision: 4.8669671415590405e-161\n",
      "Precision: 5.407741268398934e-162\n",
      "Precision: 6.008601409332149e-163\n",
      "Precision: 6.6762237881468325e-164\n",
      "Precision: 7.418026431274259e-165\n",
      "Precision: 8.242251590304732e-166\n",
      "Precision: 9.158057322560813e-167\n",
      "Precision: 1.0175619247289793e-167\n",
      "Precision: 1.130624360809977e-168\n",
      "Precision: 1.2562492897888634e-169\n",
      "Precision: 1.3958325442098483e-170\n",
      "Precision: 1.5509250491220536e-171\n",
      "Precision: 1.7232500545800595e-172\n",
      "Precision: 1.9147222828667327e-173\n",
      "Precision: 2.1274692031852587e-174\n",
      "Precision: 2.363854670205843e-175\n",
      "Precision: 2.6265051891176034e-176\n",
      "Precision: 2.9183390990195595e-177\n",
      "Precision: 3.242598998910622e-178\n",
      "Precision: 3.602887776567358e-179\n",
      "Precision: 4.003208640630398e-180\n",
      "Precision: 4.448009600700442e-181\n",
      "Precision: 4.942232889667158e-182\n",
      "Precision: 5.491369877407954e-183\n",
      "Precision: 6.101522086008837e-184\n",
      "Precision: 6.779468984454264e-185\n",
      "Precision: 7.532743316060293e-186\n",
      "Precision: 8.369714795622548e-187\n",
      "Precision: 9.299683106247276e-188\n",
      "Precision: 1.0332981229163639e-188\n",
      "Precision: 1.1481090254626265e-189\n",
      "Precision: 1.275676694958474e-190\n",
      "Precision: 1.41741854995386e-191\n",
      "Precision: 1.5749094999487333e-192\n",
      "Precision: 1.7498994443874815e-193\n",
      "Precision: 1.9443327159860904e-194\n",
      "Precision: 2.160369684428989e-195\n",
      "Precision: 2.4004107604766547e-196\n",
      "Precision: 2.667123067196283e-197\n",
      "Precision: 2.9634700746625367e-198\n",
      "Precision: 3.2927445274028187e-199\n",
      "Precision: 3.6586050304475763e-200\n",
      "Precision: 4.065116700497307e-201\n",
      "Precision: 4.516796333885897e-202\n",
      "Precision: 5.018662593206552e-203\n",
      "Precision: 5.576291770229502e-204\n",
      "Precision: 6.195879744699447e-205\n",
      "Precision: 6.88431082744383e-206\n",
      "Precision: 7.649234252715366e-207\n",
      "Precision: 8.49914916968374e-208\n",
      "Precision: 9.443499077426378e-209\n",
      "Precision: 1.0492776752695976e-209\n",
      "Precision: 1.1658640836328863e-210\n",
      "Precision: 1.2954045373698738e-211\n",
      "Precision: 1.4393383748554154e-212\n",
      "Precision: 1.5992648609504617e-213\n",
      "Precision: 1.776960956611624e-214\n",
      "Precision: 1.9744010629018045e-215\n",
      "Precision: 2.1937789587797828e-216\n",
      "Precision: 2.437532176421981e-217\n",
      "Precision: 2.708369084913312e-218\n",
      "Precision: 3.009298983237013e-219\n",
      "Precision: 3.3436655369300148e-220\n",
      "Precision: 3.7151839299222385e-221\n",
      "Precision: 4.127982144358043e-222\n",
      "Precision: 4.586646827064493e-223\n",
      "Precision: 5.096274252293881e-224\n",
      "Precision: 5.662526946993201e-225\n",
      "Precision: 6.291696607770223e-226\n",
      "Precision: 6.990774008633581e-227\n",
      "Precision: 7.767526676259535e-228\n",
      "Precision: 8.630585195843928e-229\n",
      "Precision: 9.589539106493253e-230\n",
      "Precision: 1.065504345165917e-230\n",
      "Precision: 1.1838937168510189e-231\n",
      "Precision: 1.3154374631677987e-232\n",
      "Precision: 1.461597181297554e-233\n",
      "Precision: 1.6239968681083932e-234\n",
      "Precision: 1.8044409645648814e-235\n",
      "Precision: 2.0049344050720902e-236\n",
      "Precision: 2.2277048945245448e-237\n",
      "Precision: 2.4752276605828277e-238\n",
      "Precision: 2.750252956203142e-239\n",
      "Precision: 3.055836618003491e-240\n",
      "Precision: 3.3953740200038785e-241\n",
      "Precision: 3.772637800004309e-242\n",
      "Precision: 4.191819777782566e-243\n",
      "Precision: 4.6575775308695176e-244\n",
      "Precision: 5.175086145410575e-245\n",
      "Precision: 5.750095717122861e-246\n",
      "Precision: 6.388995241247624e-247\n",
      "Precision: 7.098883601386249e-248\n",
      "Precision: 7.887648445984721e-249\n",
      "Precision: 8.764053828871912e-250\n",
      "Precision: 9.737837587635458e-251\n",
      "Precision: 1.0819819541817174e-251\n",
      "Precision: 1.2022021713130193e-252\n",
      "Precision: 1.3357801903477992e-253\n",
      "Precision: 1.4842002114975546e-254\n",
      "Precision: 1.649111346108394e-255\n",
      "Precision: 1.8323459401204377e-256\n",
      "Precision: 2.035939933467153e-257\n",
      "Precision: 2.26215548163017e-258\n",
      "Precision: 2.5135060907001887e-259\n",
      "Precision: 2.792784545222432e-260\n",
      "Precision: 3.1030939391360357e-261\n",
      "Precision: 3.447882154595595e-262\n",
      "Precision: 3.830980171772884e-263\n",
      "Precision: 4.256644635303204e-264\n",
      "Precision: 4.729605150336893e-265\n",
      "Precision: 5.255116833707659e-266\n",
      "Precision: 5.839018704119621e-267\n",
      "Precision: 6.487798560132913e-268\n",
      "Precision: 7.208665066814347e-269\n",
      "Precision: 8.00962785201594e-270\n",
      "Precision: 8.899586502239934e-271\n",
      "Precision: 9.888429446933259e-272\n",
      "Precision: 1.0987143829925844e-272\n",
      "Precision: 1.2207937588806493e-273\n",
      "Precision: 1.3564375098673882e-274\n",
      "Precision: 1.5071527887415426e-275\n",
      "Precision: 1.674614209712825e-276\n",
      "Precision: 1.8606824552364721e-277\n",
      "Precision: 2.0674249502627467e-278\n",
      "Precision: 2.297138833625274e-279\n",
      "Precision: 2.55237648180586e-280\n",
      "Precision: 2.835973868673178e-281\n",
      "Precision: 3.1510820763035312e-282\n",
      "Precision: 3.5012023070039234e-283\n",
      "Precision: 3.890224785559915e-284\n",
      "Precision: 4.322471983955461e-285\n",
      "Precision: 4.8027466488394015e-286\n",
      "Precision: 5.336385165377113e-287\n",
      "Precision: 5.929316850419014e-288\n",
      "Precision: 6.588129833798905e-289\n",
      "Precision: 7.320144259776561e-290\n",
      "Precision: 8.133493621973957e-291\n",
      "Precision: 9.037215135526619e-292\n",
      "Precision: 1.004135015058513e-292\n",
      "Precision: 1.1157055722872368e-293\n",
      "Precision: 1.2396728580969298e-294\n",
      "Precision: 1.3774142867743663e-295\n",
      "Precision: 1.5304603186381847e-296\n",
      "Precision: 1.7005114651535384e-297\n",
      "Precision: 1.8894571835039315e-298\n",
      "Precision: 2.0993968705599237e-299\n",
      "Precision: 2.3326631895110265e-300\n",
      "Precision: 2.591847988345585e-301\n",
      "Precision: 2.879831098161761e-302\n",
      "Precision: 3.1998123312908456e-303\n",
      "Precision: 3.555347034767606e-304\n",
      "Precision: 3.9503855941862293e-305\n",
      "Precision: 4.389317326873588e-306\n",
      "Precision: 4.877019252081764e-307\n",
      "Precision: 5.418910280090849e-308\n",
      "Precision: 6.021011422323166e-309\n",
      "Precision: 6.6900126914702e-310\n",
      "Precision: 7.433347434967e-311\n",
      "Precision: 8.25927492774e-312\n",
      "Precision: 9.17697214195e-313\n",
      "Precision: 1.0196635713e-313\n",
      "Precision: 1.1329595237e-314\n",
      "Precision: 1.258843915e-315\n",
      "Precision: 1.39871546e-316\n",
      "Precision: 1.5541284e-317\n",
      "Precision: 1.72681e-318\n",
      "Precision: 1.91865e-319\n",
      "Precision: 2.132e-320\n",
      "Precision: 2.367e-321\n",
      "Precision: 2.6e-322\n",
      "Precision: 3e-323\n",
      "Precision: 5e-324\n"
     ]
    }
   ],
   "source": [
    "epsilon, ratio = 1.0, 9.0 \n",
    "while (epsilon):\n",
    "    print('Precision:',epsilon) \n",
    "#     epsilon /= ratio is the samething as epsilon = epsilon/ratio\n",
    "    epsilon /= ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line indicates that the precision that standard Python assumes on my machine is $10^{−324}$. This is indeed associated to a 64-bit float number. One can verify this by setting a smaller precision in the first line of this sequence. \n",
    "\n",
    "### Exercise 3\n",
    "\n",
    "Test with the above routine the precision of the following types:\n",
    "\n",
    "a) np.float16()\n",
    "\n",
    "b) np.float32()\n",
    "\n",
    "Google now all the other types of Float available on NumPy and check which ones work on this machine (why some may not?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Precision: 0.1111\n",
      "Precision: 0.012344\n",
      "Precision: 0.001371\n",
      "Precision: 0.0001523\n",
      "Precision: 1.69e-05\n",
      "Precision: 1.9e-06\n",
      "Precision: 2.4e-07\n",
      "Precision: 1.0\n",
      "Precision: 0.11111111\n",
      "Precision: 0.012345679\n",
      "Precision: 0.0013717421\n",
      "Precision: 0.00015241579\n",
      "Precision: 1.6935088e-05\n",
      "Precision: 1.8816764e-06\n",
      "Precision: 2.0907515e-07\n",
      "Precision: 2.3230573e-08\n",
      "Precision: 2.5811748e-09\n",
      "Precision: 2.867972e-10\n",
      "Precision: 3.1866357e-11\n",
      "Precision: 3.5407064e-12\n",
      "Precision: 3.934118e-13\n",
      "Precision: 4.3712423e-14\n",
      "Precision: 4.856936e-15\n",
      "Precision: 5.3965957e-16\n",
      "Precision: 5.996218e-17\n",
      "Precision: 6.662464e-18\n",
      "Precision: 7.402738e-19\n",
      "Precision: 8.225264e-20\n",
      "Precision: 9.1391825e-21\n",
      "Precision: 1.0154648e-21\n",
      "Precision: 1.1282942e-22\n",
      "Precision: 1.2536603e-23\n",
      "Precision: 1.3929559e-24\n",
      "Precision: 1.5477288e-25\n",
      "Precision: 1.7196987e-26\n",
      "Precision: 1.9107763e-27\n",
      "Precision: 2.1230847e-28\n",
      "Precision: 2.3589831e-29\n",
      "Precision: 2.6210923e-30\n",
      "Precision: 2.9123249e-31\n",
      "Precision: 3.2359164e-32\n",
      "Precision: 3.5954625e-33\n",
      "Precision: 3.9949584e-34\n",
      "Precision: 4.4388426e-35\n",
      "Precision: 4.9320472e-36\n",
      "Precision: 5.4800523e-37\n",
      "Precision: 6.088947e-38\n",
      "Precision: 6.765497e-39\n",
      "Precision: 7.51722e-40\n",
      "Precision: 8.3524e-41\n",
      "Precision: 9.281e-42\n",
      "Precision: 1.031e-42\n",
      "Precision: 1.15e-43\n",
      "Precision: 1.3e-44\n",
      "Precision: 1e-45\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.float16(10)\n",
    "np.float32(10)\n",
    "\n",
    "epsilon, ratio = np.float16(1), np.float16(9) \n",
    "while (epsilon):\n",
    "    print('Precision:',epsilon) \n",
    "#     epsilon /= ratio is the samething as epsilon = epsilon/ratio\n",
    "    epsilon /= ratio \n",
    "# Much smaller precision\n",
    "\n",
    "epsilon, ratio = np.float32(1), np.float32(9) \n",
    "while (epsilon):\n",
    "    print('Precision:',epsilon) \n",
    "#     epsilon /= ratio is the samething as epsilon = epsilon/ratio\n",
    "    epsilon /= ratio\n",
    "# goes up exponential between 16,32, and 64 bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to float, there exist integers with several precisions: np.int32, np.int64, np.int128. The type of every NumPy variable can be retrieved the dtype, e.g., eps.dtype.\n",
    "\n",
    "It is very important to keep in mind the importance of precision. All the mathematical routines implemented in Python, as well as in any other language, follow the standards determined by IEEE which imply that they are all corrected to the last digit. Therefore, when we will model a physical system we can be sure that errors will not propagate quickly to lower digits with every algorithm that does not explicitly remove this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization \n",
    "Vectorization is a technique that allows the programmer to replace the loops in vector/matrix operations with a unique call on an entire vector, or matrix. The vectorization makes the program look simple and also facilites the parallization. \n",
    "\n",
    "Let's consider for example matrix multiplications. Here we will replance loops with vectorized calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: matrix multiplication using loop (non-vectorized algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 µs ± 284 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([[1,2],[3,4]])\n",
    "b=np.array([[5,6],[7,8]])\n",
    "c=np.zeros((2,2),int)\n",
    "\n",
    "def myMultiplication(a,b,c):\n",
    "    size=np.shape(a)[0]\n",
    "    for i in np.arange(size):\n",
    "        for j in np.arange(size):\n",
    "            sum=0;\n",
    "            for k in np.arange(size):\n",
    "                sum+=a[i, k] * b[k ,j];\n",
    "            c[i,j]=sum\n",
    "    return c\n",
    "\n",
    "%timeit myMultiplication(a,b,c)\n",
    "c= myMultiplication(a,b,c)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Matrix multiplication using vectorized algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 22]\n",
      " [43 50]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,2],[3,4]])\n",
    "b=np.array([[5,6],[7,8]])\n",
    "c=np.matmul(a,b)\n",
    "print(c)\n",
    "\n",
    "size=np.shape(a)[0]\n",
    "print(size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Create two larger arrays of measure 10 x 10 (for example using arange and reshape, but there are other ways). And multiply them with the two techniques above. If you put them in a function, you can also %timeit these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325 242 283 258 345 196 380 227 311 327]\n",
      " [299 299 291 304 341 187 349 235 282 282]\n",
      " [203 265 252 246 281 126 265 170 235 260]\n",
      " [260 159 193 229 299 132 284 213 214 254]\n",
      " [305 275 258 232 297 227 383 254 307 318]\n",
      " [290 165 130 173 227 158 285 137 267 230]\n",
      " [209 234 281 271 308 197 328 244 231 311]\n",
      " [197 182 183 222 259 119 272 200 185 259]\n",
      " [228 123 166 145 221 136 258 188 169 189]\n",
      " [285 244 260 251 339 280 380 255 347 348]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# vectorized version, create two random 10x10 matrices and multiply them by np.matmul\n",
    "ArrayOne = 10*np.random.rand(10,10)\n",
    "ArrayTwo = 10*np.random.rand(10,10)\n",
    "ArrayMult = np.matmul(ArrayOne,ArrayTwo)\n",
    "\n",
    "# Loop version, create two random 10x10 matrices\n",
    "ArrayOne = 10*np.random.rand(10,10)\n",
    "ArrayTwo = 10*np.random.rand(10,10)\n",
    "# Create empty Matrix to store the multiplied values\n",
    "ArrayZero=np.zeros((10,10),int)\n",
    "\n",
    "def myMultiplication(ArrayOne,ArrayTwo,ArrayZero):\n",
    "#     gives the value of the row count, in this case 10\n",
    "    size=np.shape(ArrayOne)[0]\n",
    "#     for i in 0 - 10.\n",
    "    for i in np.arange(size):\n",
    "#         for j in 0 - 10\n",
    "        for j in np.arange(size):\n",
    "#         set initial value for the count = 0\n",
    "            sum=0;\n",
    "#     for k in 0 - 10\n",
    "            for k in np.arange(size):\n",
    "#         for i,j,k 0 - 10 use them as the indices of the matrix and do the matrix multiplication\n",
    "                sum+=ArrayOne[i, k] * ArrayTwo[k ,j];\n",
    "                ArrayZero[i,j]=sum\n",
    "    return ArrayZero\n",
    "\n",
    "c = myMultiplication(ArrayOne,ArrayTwo,ArrayZero)\n",
    "print(c)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ndarrays\n",
    "\n",
    "Let us start looking at the vectorized arrays. The core of NumPy is the object called ndarray, a storage of large quantities of data that allows to operate fast and flexible operations on it. Let’s look at some basic examples using Jupyter in interactive mode and let's create a two-dimensional array of two rows and four columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstArr = np.array([[4,6,3,4],[2,3,6,0]], dtype=np.int8)\n",
    "firstArr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstArr.ndim # number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstArr.shape # array shape as (rows,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstArr.dtype # Out[10]: dtype(’int64’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we find is that NumPy, if given a certain set of data, automatically decides a type (generally integer or float) and defines an array of the right shape where to store them. Given a NumPy array, it is always possible to obtain its shape and data type (dtype). The main difference between ndarrays and Python data types is that the elements of ndarrays are all of a predefined and homogeneous type, which is an essential property to reach great speed for its calculations.\n",
    "\n",
    "In general, one can set the data type at the moment of creation of the array, which is a particularly useful function when one has to handle with very large models and datasets and needs to be in control of the size of the occupied memory. Data in NumPy are either int: integer, uint: unsigned integer (from 0), and float, a real number. int and uint can have sizes of 8, 16, 32, and 64 bits, while float of 16, 32, and 64 bits. If not otherwise set, automatically NumPy will set data type size to 64 bits.\n",
    "\n",
    "Most commonly used generators of ndarrays are arange, zeros and ones. Let us look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondArr = np.arange((20),dtype=np.int32)\n",
    "secondArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondArr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [14]: secondArr = np.zeros(20)\n",
    "In [15]: secondArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [16]: secondArr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [17]: secondArr = np.ones(20)\n",
    "In [18]: secondArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [19]: secondArr.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*arange()* is the analogue of *range()* in Python, but it creates a NumPy array of 64 bits integers. *zeros()* and *ones()* instead create arrays of 64 bits float. *ones()* can also be created from *zeros()* using the broadcasting properties of NumPy arrays, just by the instruction *arr=np.zeros(20)+1.0*. If we wish to create arrays with different types, for example due to operational reasons or of memory size, dtypes can be explicitly specified, \n",
    "e.g.,*arr = np.arange(20, dtype=’float32’)* or *arr = np.ones(20, dtype=’int8’)*.\n",
    "\n",
    "Let us now check how using NumPy allows to speed the calculations done earlier. The first temptation might be simply to replace *range()* with *np.arange()*. Will it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Rewrite the function *addCount()*, replacing *range* with *np.arange* and %timeit this new function. Give it a different name, to make the comparison possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.87 ms ± 611 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-9b08c1dfea05>:13: RuntimeWarning: overflow encountered in long_scalars\n",
      "  a=a+i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 ms ± 1.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# original addCount, uses range function\n",
    "def addCount(max):\n",
    "    a=0\n",
    "    for i in range(max):\n",
    "        a=a+i\n",
    "%timeit addCount(100000)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now time the same quantities of Exercise 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-b7e2466cc609>:5: RuntimeWarning: overflow encountered in long_scalars\n",
      "  a=a+i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.9 ms ± 2.11 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "234 ms ± 15.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.34 s ± 60 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# new addCount, uses arrange function\n",
    "def addCountA(max):\n",
    "    a=0\n",
    "    for i in np.arange(max):\n",
    "        a=a+i\n",
    "    \n",
    "%timeit addCountA(100000)\n",
    "%timeit addCountA(1000000)\n",
    "%timeit addCountA(10000000)\n",
    "\n",
    "#The times are pretty much the same, 7,70,700 ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you find? No acceleration?? Interesting!\n",
    "\n",
    "What happened here is that although the arrays were ndarrays, the operation was done as for a standard Python list. The trick to speed calculations on ndarrays is to use the broadcast vectorized version of each operation. Let us look at how to add two ndarrays of one million of integers either with the standard Python loop and exploiting the NumPy broadcasting capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689 ms ± 23.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def addArray(a,b):\n",
    "    c=np.zeros(a.size)\n",
    "    for i in np.arange(a.size):\n",
    "        c[i]=a[i]+b[i]\n",
    "    return(c)\n",
    "\n",
    "a=np.arange(1000000)\n",
    "b=np.arange(1000000)\n",
    "\n",
    "%timeit addArray(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679 ms ± 9.23 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit c=addArray(a,b) #standard python \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "use the broadcasting command *a+b* to sum the two arrays, as done by the routine above. How fast is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 ms ± 3.43 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=np.arange(100000)\n",
    "b=np.arange(100000)\n",
    "\n",
    "def addArray(a,b):\n",
    "    c=np.zeros(a.size)\n",
    "    for i in np.arange(a.size):\n",
    "        c[i]=a[i]+b[i]\n",
    "    return(c)\n",
    "   \n",
    "%timeit addArray(a,b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you find? A huge gain this time?! Two orders of magnitude!? Uau!\n",
    "\n",
    "To use the broadcasting feature of NumPy makes Python’s speed comparable to compiled codes such as C, but with the obvious gain in terms for code development, testing, and readability. Broadcasting is clearly not limited to the addition operation, but it works as well with all the other arithmetic operations such as c=a*b; c=a/b; c=a-b,as well as scalar-array operations like \n",
    "```python \n",
    "c=1/a; \n",
    "c=a**0.5\n",
    "```\n",
    "Besides operations on two arrays, there are numerous unary (and binary universal functions that can be used with NumPy arrays. Among unary functions, much used ones are \n",
    "```python \n",
    "np.abs()\n",
    "np.sqrt()\n",
    "np.exp()\n",
    "np.log()\n",
    "np.sign()\n",
    "```\n",
    "and all the trigonometric functions. Binary functions are \n",
    "```python \n",
    "np.add()\n",
    "np.multiply()\n",
    "np.power()\n",
    "np.maximum()\n",
    "np.mod().\n",
    "```\n",
    "\n",
    "Let us go back now to the initial problem. We wanted to sum all the elements of a large array (100 millions numbers). This is neither an unary or binary operation, because it is a function that projects an array into one number, the sum. The most common among these operations are already efficiently implemented in NumPy. For example, the sum is immediately obtained by *np.arange(max).sum()*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "use the *sum()* call to sum the first 10000000 numbers. How faster is this operation compared to the routine developed earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   2.   4.   6.   8.  10.  12.  14.  16.  18.  20.  22.  24.  26.\n",
      "  28.  30.  32.  34.  36.  38.  40.  42.  44.  46.  48.  50.  52.  54.\n",
      "  56.  58.  60.  62.  64.  66.  68.  70.  72.  74.  76.  78.  80.  82.\n",
      "  84.  86.  88.  90.  92.  94.  96.  98. 100. 102. 104. 106. 108. 110.\n",
      " 112. 114. 116. 118. 120. 122. 124. 126. 128. 130. 132. 134. 136. 138.\n",
      " 140. 142. 144. 146. 148. 150. 152. 154. 156. 158. 160. 162. 164. 166.\n",
      " 168. 170. 172. 174. 176. 178. 180. 182. 184. 186. 188. 190. 192. 194.\n",
      " 196. 198.]\n",
      "179 ms ± 31 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# here you can make your test\n",
    "a=np.arange(100)\n",
    "b=np.arange(100)\n",
    "c=np.zeros(a.size)\n",
    "\n",
    "def addArraySum(a,b):\n",
    "    c=np.zeros(a.size)\n",
    "    for i in np.arange(a.size):\n",
    "        c[i]=sum((a[i],b[i]))\n",
    "    return(c)\n",
    "\n",
    "test=addArraySum(a,b)\n",
    "print(test)\n",
    "\n",
    "\n",
    "a=np.arange(100000)\n",
    "b=np.arange(100000)\n",
    "%timeit addArraySum(a,b) \n",
    "# with a 100,000 matrix then the time is 179 ms, which is slower then just doing it manually with a + command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operations have been in fact written in Cython, which is a C compiled operation. We will see later in this chapter how such operations, when not already implemented in NumPy, can (not easily!) be created using Cython."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing\n",
    "\n",
    "Most languages today are compiled. One of the great features of compilers is that when we have to perform a set of repetitive operations on a large set of data, the compiler will take care to optimize these iterations in an exceptional way, even if we wrote a very confusing code. This is not the case with a language like Python.\n",
    "\n",
    "If we want our Python code to run fast, we have to organize the sequence of operation in a smart way. In particular a very common case like calling an **if** command inside a for loop can make Python very slow. We have seen above how looping makes Python slow. One of the secrets that make Python fast is to use smart indexing. To use indexing, in practice it means to vectorize the command **if** and then to use these indexes to selectively operate on arrays. This might seem a terrible setback for Python programmers, however the great advantage of forcing the developer to do this operation is that the program will be written in a completely vectorized way from the start, therefore ready to be parallelized, which is in fact a huge advantage.\n",
    "\n",
    "Indexing and slicing in NumPy is a long topic, whose full coverage goes beyond the scope of this series of Notebooks. To gain a full understanding of the possibilities offered by NumPy, I recommend to follow one of the online free tutorials (e.g., https://docs.scipy.org/doc/numpy-dev/user/basics.indexing.html). I will cover here some of the main features, and explain in depth important details on the memory management associated to ndarrays.\n",
    "\n",
    "Let us now dive into the main features that interest us. Given an array, e.g., **arr**, we can access the element n with square brackets **arr[n]** and we can slice the array extracting the elements between n and m with the command **arr[n:m]**, which will return m − n elements (comprising **arr[n]** and excluding **arr[m]**. It is very important to understand that even if we associate a name to the slice of arr, this is only a view, not a new array implying that the m − n elements are not copied in a new allocated chunk of memory. This means that by changing the sliced array you will change the initial data. Let us look at an example to clearly understand how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondArr=np.arange(20)\n",
    "secondArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliceArr = secondArr[4:10]\n",
    "print(sliceArr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliceArr[3]=100000\n",
    "sliceArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who is familiar with other languages might be surprised by this behavior, and believe that when defining sliceArr Python should have copied the subset of second **Arr** data into a new array. The point is that NumPy has been designed to deal with very large datasets or numerical models, therefore it uses a policy of minimization of memory usage. For this reason, if one does not force NumPy to create a copy of the sliced data, it will simply generate a *view* of the already existing array. NumPy can be forced to create a separate new array by adding **.copy()** to the slice, e.g., in our case **sliceArr = secondArr[4:10].copy()**.\n",
    "\n",
    "Slicing is very flexible and allows omitting, for example, the first index (e.g., **arr[:10]**) or the last index (e.g., **arr[10:]**) of a slice, which implies that the slice reaches the end of the array. It is also possible to slice the array every k elements by indicating a third parameter in the slice (e.g., **arr[4:12:3]**), and also omitting the other parameters (e.g., **arr[::3]**). Negative indexes are also admitted, which means that counting starts from the last element, backward, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondArr[::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-Dimensional Indexing\n",
    "Indexing and slicing in more dimensions are just a recursive repetition of one-dimensional operations. In 2D, for example, arrays can be indexed either as **arr2d[n][m]** or, with the same effect, as **arr2d[n,m]**. The first index refers to the inner array, the second index to the outer array. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d = np.arange(20)\n",
    "sliceArr = arr2d[4:10]\n",
    "arr2dnew=arr2d.reshape((5,4))\n",
    "arr2dnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2dnew[4,3]=10000\n",
    "print(arr2dnew)\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliceArr[3]=100\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2dnew[:,0]=100.\n",
    "print(arr2dnew)\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to remember that the reshape command does not create a copy of the data, as well as slicing. **The data remain stored in the memory as a one-dimensional array, regardless of the dimensions and shape of the array**. The way in which this is done and how NumPy broadcasting operations remain extremely efficient is explained later, where strides are illustrated. \n",
    "\n",
    "Data analysis with Python is a huge topic. A great book that analyzes in greater detail how Python can deal with data is McKinney,W.(2012) Python for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "Create a (a) 1d, (b) 2d, and (c) 3d dimensional array, and, slice it, change some value of the slice, and verify that that the value of the initial array changed, too. \n",
    "\n",
    "Now, let's create the slice with the command *myArray.copy()* and check what happens when you change the value of an elements of the slice. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "This is slice of a PlayArray: [ 5  6  7  8  9 10]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]\n",
      " [17 18 19 20]]\n",
      "[[   1    2    3    4]\n",
      " [   5    6    7    8]\n",
      " [   9   10   11   12]\n",
      " [  13   14   15   16]\n",
      " [  17   18   19 9999]]\n",
      "[[   1    2    3    4]\n",
      " [   5    6    7    8]\n",
      " [   9   10   11   12]\n",
      " [  13   14   15   16]\n",
      " [  17   18   19 1111]]\n",
      "[[   1    2    3    4]\n",
      " [   5    6    7    8]\n",
      " [   9   10   11   12]\n",
      " [  13   14   15   16]\n",
      " [  17   18   19 2020]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# here you can put your solutions\n",
    "PlayArray = np.arange(1,21)\n",
    "print(PlayArray)\n",
    "\n",
    "# Give Slice\n",
    "GiveSlice = PlayArray[4:10]\n",
    "print('This is slice of a PlayArray:',GiveSlice)\n",
    "\n",
    "# Reshapes the array into a 5row, by 4 column matrix, using the same values\n",
    "ReshapedPlayArray = PlayArray.reshape((5,4))\n",
    "print(ReshapePlayArray)\n",
    "\n",
    "# ReshapedPlayArray[4,3] grabs the 4th row, 3rd column value. Keeping in mind that 0 is the first row first column value.\n",
    "# print(ReshapedPlayArray[4,3])\n",
    "ReshapedPlayArray[4,3] = 9999\n",
    "print(ReshapedPlayArray)\n",
    "\n",
    "# copies the whole matrix, changes a value using .copy\n",
    "ReshapedPlayArray=ReshapedPlayArray.copy()\n",
    "# print(ReshapedPlayArray)\n",
    "ReshapedPlayArray[4,3] = 1111\n",
    "print(ReshapedPlayArray)\n",
    "\n",
    "# copies the whole matrix, changes a value using np.copy\n",
    "ReshapedPlayArray=np.copy(ReshapedPlayArray)\n",
    "# print(ReshapedPlayArray)\n",
    "ReshapedPlayArray[4,3] = 2020\n",
    "print(ReshapedPlayArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing\n",
    "\n",
    "Sometimes you have to operate with *if* commands on a large dataset, but you don't want to create a loop which would immensely slow down the data processing. A practical tool to do that efficiently is to use boolean indexing.\n",
    "\n",
    "Boolean indexing is a fast and efficient way to select, access and operate on subsets of a NumPy arrays. Let us for example create a random 5 × 5 matrix (array) and select only the positive elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.31870599e+00 -8.99718245e-01 -2.29715761e-01 -1.39887654e-01\n",
      "  -7.89530701e-01]\n",
      " [ 2.07369012e+00 -1.92003374e-03 -4.54054705e-01  1.05325638e+00\n",
      "  -1.07399153e+00]\n",
      " [ 1.70279242e+00 -5.12235862e-01 -2.15650131e+00 -7.96528098e-02\n",
      "   3.59466844e-01]\n",
      " [ 5.83661776e-01 -1.25095248e+00  1.36315074e+00 -1.38567091e+00\n",
      "  -1.57550711e+00]\n",
      " [ 3.45118528e-01 -5.79894629e-01 -5.18049345e-01 -3.04184467e-01\n",
      "  -2.41879775e-01]]\n",
      "-0.13574018224184103\n"
     ]
    }
   ],
   "source": [
    "arr2d = np.random.randn(5,5)\n",
    "print(arr2d)\n",
    "print(arr2d.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False],\n",
       "       [ True, False, False,  True, False],\n",
       "       [ True, False, False, False,  True],\n",
       "       [ True, False,  True, False, False],\n",
       "       [ True, False, False, False, False]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31870599, 2.07369012, 1.05325638, 1.70279242, 0.35946684,\n",
       "       0.58366178, 1.36315074, 0.34511853])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[arr2d>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did was to create a 5×5 array whose values were True when the elements were positive, and False in the opposite case. It was then possible to select only those elements. It is important to notice that the extracted elements have lost their 5 × 5 structure. This again results from the fact that Python stores every array, regardless of its shape, as a 1D array.\n",
    "\n",
    "This technique is normally used to operate on a certain subset of an array. For example if we desire to set to 0 all the negative elements of the above array, we can do it with one instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d[arr2d<0]=0.\n",
    "arr2d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "Create a 9 x 9 array of random integers between 0 and 9, and set to -1 all the numbers that are less than 5 with one command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 7 7 4 2 9 6 0 0]\n",
      " [5 0 6 1 6 2 6 3 2]\n",
      " [9 4 4 5 8 8 5 3 7]\n",
      " [5 4 2 3 0 5 1 3 0]\n",
      " [5 6 9 8 3 0 4 9 0]\n",
      " [4 8 0 4 4 1 7 2 6]\n",
      " [4 0 4 4 6 1 7 9 7]\n",
      " [1 8 9 3 6 8 9 9 6]\n",
      " [8 2 9 8 7 1 1 0 6]]\n",
      "[[ True False False  True  True False False  True  True]\n",
      " [False  True False  True False  True False  True  True]\n",
      " [False  True  True False False False False  True False]\n",
      " [False  True  True  True  True False  True  True  True]\n",
      " [False False False False  True  True  True False  True]\n",
      " [ True False  True  True  True  True False  True False]\n",
      " [ True  True  True  True False  True False False False]\n",
      " [ True False False  True False False False False False]\n",
      " [False  True False False False  True  True  True False]]\n",
      "[2 4 2 0 0 0 1 2 3 2 4 4 3 4 2 3 0 1 3 0 3 0 4 0 4 0 4 4 1 2 4 0 4 4 1 1 3\n",
      " 2 1 1 0]\n",
      "[[-1  7  7 -1 -1  9  6 -1 -1]\n",
      " [ 5 -1  6 -1  6 -1  6 -1 -1]\n",
      " [ 9 -1 -1  5  8  8  5 -1  7]\n",
      " [ 5 -1 -1 -1 -1  5 -1 -1 -1]\n",
      " [ 5  6  9  8 -1 -1 -1  9 -1]\n",
      " [-1  8 -1 -1 -1 -1  7 -1  6]\n",
      " [-1 -1 -1 -1  6 -1  7  9  7]\n",
      " [-1  8  9 -1  6  8  9  9  6]\n",
      " [ 8 -1  9  8  7 -1 -1 -1  6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# generate 9x9 random integer matrix\n",
    "RandomNine = np.random.randint(10, size=[9,9])\n",
    "print(RandomNine)\n",
    "\n",
    "# Logical\n",
    "print(RandomNine<5)\n",
    "# Returns the value of the Trues\n",
    "print(RandomNine[RandomNine<5])\n",
    "\n",
    "# Set the values less than 5 = to -1\n",
    "RandomNine[RandomNine<5] = -1\n",
    "print(RandomNine)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides compactness and elegance, this technique guarantees an enormous gain in speed. To quantify this advantage, we can compare the time necessary for a standard Python for loop with the Boolean indexing tool described above for a large 2000 × 2000 random array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d=np.random.randn(2000,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.59 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def setNegativeValuesToZero(n,m,a): \n",
    "    for i in np.arange(n):\n",
    "        for j in np.arange(m):\n",
    "            if a[i,j]<0:\n",
    "                a[i,j]=0\n",
    "%timeit -n1 -r1 setNegativeValuesToZero(2000,2000,arr2d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "Do the operation of done by the function *setNegativeValuesToZero(n,m,a)* with boolean arrays. How faster than that is it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.30476365 -0.38724894  2.32093413 ...  1.5911068   1.06414517\n",
      "   1.16310457]\n",
      " [-0.55408881  0.97291255 -2.32998853 ...  1.87825299 -1.80929884\n",
      "  -1.65084852]\n",
      " [-0.38847041 -0.30399734 -0.53662645 ... -0.6694199   1.96571208\n",
      "  -0.12376814]\n",
      " ...\n",
      " [-1.9895746   0.8994903   0.06246684 ...  0.19015861  0.84580593\n",
      "  -1.13526166]\n",
      " [ 0.07367752 -1.7197602  -1.09447093 ... -0.74828098  0.99167708\n",
      "  -0.94961509]\n",
      " [ 0.15520992 -0.09528188 -1.43754735 ...  0.88656397  0.44314288\n",
      "  -0.46327187]] 10\n",
      "5.8 ms ± 257 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "RandomBigMatrix = np.random.randn(2000,2000)\n",
    "# Prints the first and last 10 values of the Random Big Matrix\n",
    "print(RandomBigMatrix, 10)\n",
    "\n",
    "%timeit RandomBigMatrix[RandomBigMatrix<0] = 0\n",
    "# A thousand times faster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we observe a gain of 2 orders of magnitude by using the NumPy indexing compared to standard Python loops. The message is now loud and clear: never use Python loops for large datasets and large numerical models, but always employ Python indexing/slicing features to achieve compiled code performance for speed and memory management. When not possible, rely on Cython, that we will study soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposing and Axis Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already encountered the function reshape, which allows to project a 1D array as a generic n-dimensional array. One operation that cannot be achieved by reshaping is however transposing, which corresponds to swapping axis. This is a very important function when operating on 2D and 3D numerical modeling, but it is also simply essential in order to calculate the inner product. For example, to calculate Xtranspose * X , one writes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "arr2d = np.random.randn(n)\n",
    "arr2d\n",
    "arr2d=arr2d.reshape(5,int(n/5))\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newArr=np.dot(arr2d.T,arr2d)\n",
    "print(newArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing, however, is not limited to swapping x and y axis. One can rotate axis as well. For example in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3d = np.arange(2*3*4).reshape(2,3,4)\n",
    "arr3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3d2 = arr3d.transpose((2,0,1)).copy()\n",
    "print(arr3d.shape)\n",
    "print(arr3d2.shape)\n",
    "arr3d[1,0,0]=1000\n",
    "arr3d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing, as well as reshaping, is just a specific view of the entire array, therefore **transposing will not create a new set of data**, and when modifying the transposed of an array, one modifies the original array as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "\n",
    "Calculate the euclidean norm of a 1D array of random numbers  by using transpose to multiply two vectors, and then check that the result is correct using the function *numpy.linalg.norm*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 9]]\n",
      "9.848857801796104\n",
      "[[4]\n",
      " [9]]\n",
      "[[16 36]\n",
      " [36 81]]\n",
      "9.848857801796104\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "RandomArray = np.random.randint(10, size = [1,2])\n",
    "print(RandomArray)\n",
    "\n",
    "Norm = np.linalg.norm(RandomArray)\n",
    "print(Norm)\n",
    "\n",
    "\n",
    "TransposedArray = np.transpose(RandomArray)\n",
    "print(TransposedArray)\n",
    "\n",
    "SquaredComponents = RandomArray*TransposedArray\n",
    "print(SquaredComponents)\n",
    "\n",
    "Norm = np.sqrt(SquaredComponents[0,0]+SquaredComponents[1,1])\n",
    "print(Norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strides\n",
    "\n",
    "The technical details given here help to understand how NumPy deals with very large arrays minimizing memory occupation and maximizing access speed.\n",
    "\n",
    "It is important to emphasize that although an array can have many dimensions, the memory in our computer is structured in a purely sequential way, therefore ultimately the real structure of the array is one-dimensional, and every n-dimensional array will only be a specific view on that 1D array.\n",
    "\n",
    "NumPy is extraordinary powerful in managing n-dimensional arrays, different views, complex subsets, for example\n",
    "\n",
    "```python\n",
    "arr[arr*arr<1]. ```\n",
    "\n",
    "This power is based on the ability to directly address chunks of data by striding across the\n",
    "memory and zooming into small blocks of memory. For example, let us take a random 100 × 100 × 100 array of np.float64 data, equivalent to a 1D array of one million elements, occupying 8 bytes each. A block within the array can be extracted in microseconds, almost regardless to the size of the block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3d=np.random.randn(100,100,100)\n",
    "print(arr3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r1 newArray=arr3d[45:55,45:55,45:55].copy() #small block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r1 newArray2=arr3d[15:85,15:85,15:85].copy() #large block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we operate on the subset of the array however the operational time increases with the size of the block, although not in a proportional way. For example, to set the values of the subset to zero we need about 20 times more time for a subset that is over 300 times greater:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r1 arr3d[45:55,45:55,45:55]=0 #small block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r1 arr3d[15:85,15:85,15:85]=0 #large block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "\n",
    "Measure the time necessary to set to zero a block of size 10x10x10, 20x20x20, 30x30x30 etc for the big random array arr3d 100x100x100 illustrated above in this section. Plot the time vs size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00100255]\n",
      " [0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2216e59f310>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 3D 100x100x100 array of random numbers between positive and negative 10\n",
    "Array3D = np.random.randn(100,100,100)\n",
    "\n",
    "# Start time\n",
    "StartTime = time.time()\n",
    "\n",
    "# Index a chunk of the 3D array to zero.\n",
    "Array3D[0:80,0:80,0:80]=0\n",
    "\n",
    "# End Time\n",
    "EndTime = time.time()\n",
    "\n",
    "#Determine how long it took using the time command to use its value on our plot. Time outputs in seconds.\n",
    "TimeChange = EndTime - StartTime \n",
    "\n",
    "# Store time values\n",
    "TimeArray = np.zeros((2,1))\n",
    "TimeArray[0]=TimeChange\n",
    "\n",
    "\n",
    "#Repeat chunk = to 0 with time\n",
    "StartTime = time.time()\n",
    "Array3D[80:300,80:300,80:300]=0\n",
    "EndTime = time.time()\n",
    "TimeChange = EndTime - StartTime \n",
    "TimeArray[1]=TimeChange\n",
    "\n",
    "\n",
    "size=[80,220]\n",
    "plt.scatter(TimeArray,size) \n",
    "\n",
    "# Time is actually decreasing as I increase the size, but I believe this is because my computer processor is adjusting?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy accesses n-dimensional arrays and its slices as fast as one-dimensional arrays. To understand how this is achieved, let us consider, for example an array a of 32000 integers and then create a reshaped three-dimensional 20 × 40 × 40 version assigned to b. In our case a is composed by 64-bit (8 bytes) integers, which means that one needs to proceed 8 bytes forward to access the next element along the first axis. The size of every element can be also in general assessed with a.itemsize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(32000)\n",
    "b=a.reshape(20,40,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n"
     ]
    }
   ],
   "source": [
    "print(a.itemsize,b.itemsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be stored in memory in a buffer that contains 32000 ascending integers from 0 to 31999. As we have seen before a and b are stored in the same memory block. The way in which NumPy differentiates how to operate on them is by characterizing them by their different strides. Strides are tuples of bytes to step in each dimension when traversing an array. In practice they are the offset in bytes between an element and the neighboring one in every direction. Strides are shown explicitly using the instruction arr.strides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000,) (4,)\n",
      "(20, 40, 40) (6400, 160, 4)\n",
      "320 12800\n"
     ]
    }
   ],
   "source": [
    "print(a.shape,a.strides)\n",
    "print(b.shape,b.strides)\n",
    "print(8*40,8*40*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last number, 8, of the strides refers to the size of each element in the array, i.e., it is always the itemsize. The other numbers refer to the number of bytes forward necessary to access the next element along the other axes. The total number of bytes is called offset and is calculated as offset = sum(indexes * a.strides). For example, for the initial array a[n] every element is accessed at the position \n",
    "```python\n",
    "offset = n*a.strides[0]\n",
    "```\n",
    ", while b[i,j,k] is accessed calculating its associated memory offset as \n",
    "```python\n",
    "offset = i*b.strides[0]+j*b.strides[1]+k*b.strides[2]\n",
    "```\n",
    "in bytes. To obtain the element location one has to divide by b.itemsize. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3324"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3324.0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*b.strides[0]+3*b.strides[1]+4*b.strides[2])/b.itemsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13\n",
    "\n",
    "Create a four dimensional array from of size 3x7x4x5 and verify that the element (2,5,1,4) is the same both using strides and using the python indeces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "[[[[  0   1   2   3   4]\n",
      "   [  5   6   7   8   9]\n",
      "   [ 10  11  12  13  14]\n",
      "   [ 15  16  17  18  19]]\n",
      "\n",
      "  [[ 20  21  22  23  24]\n",
      "   [ 25  26  27  28  29]\n",
      "   [ 30  31  32  33  34]\n",
      "   [ 35  36  37  38  39]]\n",
      "\n",
      "  [[ 40  41  42  43  44]\n",
      "   [ 45  46  47  48  49]\n",
      "   [ 50  51  52  53  54]\n",
      "   [ 55  56  57  58  59]]\n",
      "\n",
      "  [[ 60  61  62  63  64]\n",
      "   [ 65  66  67  68  69]\n",
      "   [ 70  71  72  73  74]\n",
      "   [ 75  76  77  78  79]]\n",
      "\n",
      "  [[ 80  81  82  83  84]\n",
      "   [ 85  86  87  88  89]\n",
      "   [ 90  91  92  93  94]\n",
      "   [ 95  96  97  98  99]]\n",
      "\n",
      "  [[100 101 102 103 104]\n",
      "   [105 106 107 108 109]\n",
      "   [110 111 112 113 114]\n",
      "   [115 116 117 118 119]]\n",
      "\n",
      "  [[120 121 122 123 124]\n",
      "   [125 126 127 128 129]\n",
      "   [130 131 132 133 134]\n",
      "   [135 136 137 138 139]]]\n",
      "\n",
      "\n",
      " [[[140 141 142 143 144]\n",
      "   [145 146 147 148 149]\n",
      "   [150 151 152 153 154]\n",
      "   [155 156 157 158 159]]\n",
      "\n",
      "  [[160 161 162 163 164]\n",
      "   [165 166 167 168 169]\n",
      "   [170 171 172 173 174]\n",
      "   [175 176 177 178 179]]\n",
      "\n",
      "  [[180 181 182 183 184]\n",
      "   [185 186 187 188 189]\n",
      "   [190 191 192 193 194]\n",
      "   [195 196 197 198 199]]\n",
      "\n",
      "  [[200 201 202 203 204]\n",
      "   [205 206 207 208 209]\n",
      "   [210 211 212 213 214]\n",
      "   [215 216 217 218 219]]\n",
      "\n",
      "  [[220 221 222 223 224]\n",
      "   [225 226 227 228 229]\n",
      "   [230 231 232 233 234]\n",
      "   [235 236 237 238 239]]\n",
      "\n",
      "  [[240 241 242 243 244]\n",
      "   [245 246 247 248 249]\n",
      "   [250 251 252 253 254]\n",
      "   [255 256 257 258 259]]\n",
      "\n",
      "  [[260 261 262 263 264]\n",
      "   [265 266 267 268 269]\n",
      "   [270 271 272 273 274]\n",
      "   [275 276 277 278 279]]]\n",
      "\n",
      "\n",
      " [[[280 281 282 283 284]\n",
      "   [285 286 287 288 289]\n",
      "   [290 291 292 293 294]\n",
      "   [295 296 297 298 299]]\n",
      "\n",
      "  [[300 301 302 303 304]\n",
      "   [305 306 307 308 309]\n",
      "   [310 311 312 313 314]\n",
      "   [315 316 317 318 319]]\n",
      "\n",
      "  [[320 321 322 323 324]\n",
      "   [325 326 327 328 329]\n",
      "   [330 331 332 333 334]\n",
      "   [335 336 337 338 339]]\n",
      "\n",
      "  [[340 341 342 343 344]\n",
      "   [345 346 347 348 349]\n",
      "   [350 351 352 353 354]\n",
      "   [355 356 357 358 359]]\n",
      "\n",
      "  [[360 361 362 363 364]\n",
      "   [365 366 367 368 369]\n",
      "   [370 371 372 373 374]\n",
      "   [375 376 377 378 379]]\n",
      "\n",
      "  [[380 381 382 383 384]\n",
      "   [385 386 387 388 389]\n",
      "   [390 391 392 393 394]\n",
      "   [395 396 397 398 399]]\n",
      "\n",
      "  [[400 401 402 403 404]\n",
      "   [405 406 407 408 409]\n",
      "   [410 411 412 413 414]\n",
      "   [415 416 417 418 419]]]]\n",
      "389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "389.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# here you can insert your solution\n",
    "TotalVals = 3*7*4*5\n",
    "ArangeVals = np.arange(TotalVals)\n",
    "print(np.size(ValuesTotal))\n",
    "\n",
    "# There becomes three lists, each lists contains seven matrices, of four rows, five columns\n",
    "MatrixFourD=ArangeVals.reshape(3,7,4,5)\n",
    "print(MatrixFourD)\n",
    "# This indexes to the third list, sixth matrix, second row, fifth column, because you have to count zero.\n",
    "print(MatrixFourD[2,5,1,4])\n",
    "\n",
    "\n",
    "# Now use strides, Strides outputs t\n",
    "[a,b,c,d]=MatrixFourD.strides\n",
    "# Divide by itemsize because stride is litterally counting bytes not where it is indexed.\n",
    "(((2*a)+(5*b)+(1*c)+(4*d))/MatrixFourD.itemsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Vector Product\n",
    "\n",
    "The inner product, np.dot() in NumPy, is the most common operation between arrays. It is equivalent to the inner product between 1-D arrays or to matrix multiplication between 2D arrays. It is defined on n-dimensional arrays as the sum product over the last axis of the first array and the second-to-last of the second array. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(np.random.rand(1000),b=np.random.rand(1000))/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will give you a number close to 0.25, since np.random.rand() is a uniformly extracted random number between 0 and 1. Similarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(np.random.rand(100,100),b=np.random.rand(100,100))/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will result in a 100 × 100 matrix of numbers normally distributed around 0.25. \n",
    "\n",
    "Outer products are called by np.outer() and are an easy way to create an x, y regular mesh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(0,11,1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.ones(11)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.outer(a,b)\n",
    "#print(x)\n",
    "x2=np.outer(b,a)\n",
    "#print(x2)\n",
    "(x-x2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.outer(b,a)\n",
    "plt.plot(x,y,'o');plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy allows composing large arrays combining blocks of one array scaled by another. This operation is called Kronecker product, and we will intensively use it to build large operators for two-dimensional continuum mechanics. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix=np.kron(np.eye(3), np.ones((2,2)))\n",
    "print(mix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14\n",
    "\n",
    "Using *np.kron()*, *np.ones()*, *np.zeros()*, etc Create a matrix made of 6x6 blocks, each of 3x3 matrix of 0,1,2. You choose the shape of the 3x3 matrix, the coolest you can come up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [2 1 0]\n",
      " [0 1 2]]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "[[0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]\n",
      " [2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0. 2. 1. 0.]\n",
      " [0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2. 0. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[0,1,2],[2,1,0],[0,1,2]])\n",
    "print(a)\n",
    "\n",
    "b = np.ones((6,6))\n",
    "print(b)\n",
    "\n",
    "#Kronecker Product\n",
    "bigM = np.kron(b,a)\n",
    "print(bigM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "\n",
    "All the linear algebra tools that we will need are already efficiently implemented through the standard optimized ATLAS LAPACK and BLAS libraries. Ultimately all linear algebra routines expect to operate on a 2-dimensional array. There is also a matrix type in NumPy but its use is discouraged since it is possible to obtain the same result by using arrays only.\n",
    "\n",
    "Linear algebra has many subprograms that run routines for decompositions such as Cholesky, QR and Singular Value. They can be very important for many problems, however they do not apply for the problems that we will address in this volume. The interested reader can refer to the regularly updated SciPy manual at http://docs.scipy.org/doc/numpy/reference/routines.linalg.html. \n",
    "\n",
    "Linear algebra (LA) routines are accessed through the module numpy.linalg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.linalg as linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An often employed tool is linalg.norm() both for calculating the size of a 1D (vector) and 2D (matrix) arrays. Norm, that is just the square root of the sum of the square of all the elements of a n-dimensional array, could be also calculated by the definition, but the numpy.linalg implementation can be one order of magnitude as more efficient. Let us for example benchmark the calculation of a 100 × 100 array norm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(-1000,1001,1)\n",
    "b=np.arange(2001)\n",
    "x=np.outer(a,b); \n",
    "normVectorized=np.sqrt(np.sum(np.sum(x**2)))\n",
    "%timeit -n1 -r1 normVectorized=np.sqrt(np.sum(np.sum(x**2)))\n",
    "print(normVectorized)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linalg.norm(x))\n",
    "%timeit -n 1 -r1 linalg.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinants are often employed in linear algebra because they are related to the invertibility of a matrix, and on whether the associated linear system of equations is solvable (a smaller determinant can indicate that some eigenvalues are close to zero, which makes inversion harder). However, to calculate the determinant of extremely large 2D arrays as we will often do in this volume is computationally so demanding that we will do it only for small problems. Let us calculate the determinant of few random matrices, 10 × 10 and 100 × 100, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dets=np.zeros(10)\n",
    "for i in np.arange(10): dets[i]=linalg.det(np.random.rand(10,10))\n",
    "dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(10): dets[i]=linalg.det(np.random.rand(100,100))\n",
    "dets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
